# REDSHIFT
function redshift_log {
envfile=$1
source $envfile
echo $POSTGRES_PASS
PGPASSWORD=$POSTGRES_PASS psql -h $POSTGRES_HOST -U $POSTGRES_USER -p $POSTGRES_PORT $POSTGRES_DATABASE -c "select table_name, query, line_number, colname, starttime, reason as error from loadview order by line_number limit 10;"
}

# PSQL
function postgres_wrapper
{
url=$1
shift

credentials=$(echo $url | cut -d '@' -f 1 | cut -d '/' -f 3)
user=$(echo $credentials | cut -d ':' -f 1)
password=$(echo $credentials | cut -d ':' -f 2-)
address=$(echo $url | cut -d '@' -f 2)
host_port=$(echo $address | cut -d '/' -f -1)
host=$(echo $host_port | cut -d ':' -f -1)
port=$(echo $host_port | cut -d ':' -f 2-)
db=$(echo $address | cut -d '/' -f 2-)

PGPASSWORD=$password psql -h $host -U $user -p $port $db
}

# MONGO
function mongo_wrapper
{
proto="$(echo $1 | grep :// | sed -e's,^\(.*://\).*,\1,g')"
url="$(echo ${1/$proto/})"
credentials="$(echo $url | grep @ | cut -d@ -f1)"
user="$(echo $credentials | cut -d: -f1)"
password="$(echo $credentials | cut -d: -f2)"
host="$(echo ${url/$credentials@/} | cut -d/ -f1)"
db="$(echo $url | grep / | cut -d/ -f2-)"

shift
mongo $host/$db -u $user -p $password $@
}

function mongoexport_wrapper {
url=$1
shift

credentials=$(echo $url | cut -d '@' -f 1 | cut -d '/' -f 3)
user=$(echo $credentials | cut -d ':' -f 1)
password=$(echo $credentials | cut -d ':' -f 2-)
address=$(echo $url | cut -d '@' -f 2)
host=$(echo $address | cut -d '/' -f -1)
db=$(echo $address | cut -d '/' -f 2-)
echo "[$0] exporting from [$address] with user [$user]"
mongoexport -u $user -p $password \
--host $host \
--db $db \
$@
}

function mongodump_wrapper {
url=$1
shift

credentials=$(echo $url | cut -d '@' -f 1 | cut -d '/' -f 3)
user=$(echo $credentials | cut -d ':' -f 1)
password=$(echo $credentials | cut -d ':' -f 2-)
address=$(echo $url | cut -d '@' -f 2)
host=$(echo $address | cut -d '/' -f -1)
db=$(echo $address | cut -d '/' -f 2-)
echo "[$0] exporting from [$address] with user [$user]"
mongodump -u $user -p $password \
--host $host \
--db $db \
$@
}

function mongorestore_wrapper {
url=$1
shift

credentials=$(echo $url | cut -d '@' -f 1 | cut -d '/' -f 3)
user=$(echo $credentials | cut -d ':' -f 1)
password=$(echo $credentials | cut -d ':' -f 2-)
address=$(echo $url | cut -d '@' -f 2)
host=$(echo $address | cut -d '/' -f -1)
db=$(echo $address | cut -d '/' -f 2-)
echo "[$0] exporting from [$address] with user [$user]"
mongorestore -u $user -p $password \
--host $host \
--db $db \
$@
}

# REDIS
function redis_wrapper {
url=$1
credentials=$(echo $url | cut -d '@' -f 1 | cut -d '/' -f 3)
user=$(echo $credentials | cut -d ':' -f 1)
password=$(echo $credentials | cut -d ':' -f 2-)
address=$(echo $url | cut -d '@' -f 2)
host=$(echo $address | cut -d ':' -f 1)
port=$(echo $address | cut -d ':' -f 2-)
#Â echo "[$0] connecting to [$address] with user [$user]"
redis-cli -h $host -p $port -a $password
}

# UTILS
function reduce_video() {
  file="$1"
  full_basename=${file%.*}
  SUFFIX="_small"
  small_file="$full_basename"$SUFFIX.MOV
  if [[ "$file" == *"$SUFFIX"* ]];then
    echo "$file already small"
  else
    echo "ffmpeg $file -c:a copy $small_file"
    ffmpeg -n -i "$file" -c:a copy "$small_file"
  fi
}


function extract () {
    if [ -f $1 ] ; then
      case $1 in
        *.tar.bz2)   tar xjf $1     ;;
        *.tar.gz)    tar xzf $1     ;;
        *.bz2)       bunzip2 $1     ;;
        *.rar)       unrar e $1     ;;
        *.gz)        gunzip $1      ;;
        *.tar)       tar xf $1      ;;
        *.tbz2)      tar xjf $1     ;;
        *.tgz)       tar xzf $1     ;;
        *.zip)       unzip $1       ;;
        *.Z)         uncompress $1  ;;
        *.7z)        7z x $1        ;;
        *)     echo "'$1' cannot be extracted via extract()" ;;
         esac
     else
         echo "'$1' is not a valid file"
     fi
}

function moi () {
    for i in *.jpeg
    do
        dossier=`ls -l --time-style=+%Y-%m-%d "$i" | cut -d' ' -f6`
        echo $dossier
        mkdir -p "$dossier"
        mv "$i" "$dossier"
    done
}

function waouh () {
    # Function to shuffle an array
    shuffle() {
        local i tmp size max rand
        size=${#files[@]}
        max=$(( 32768 / size * size ))

        for ((i=size-1; i>0; i--)); do
            while (( (rand=RANDOM) >= max )); do :; done
            rand=$(( rand % (i+1) ))
            tmp=${files[i]} files[i]=${files[rand]} files[rand]=$tmp
        done
    }

    declare -A files_by_day
    declare -a all_files
    declare -a all_files_with_dates

    # Find files and process them
    while IFS= read -r -d '' file; do
        # Get access time and convert it to a human-readable format
        atime=$(stat -c %x "$file" | cut -d ' ' -f1)

        # Append file to the array of its access day
        files_by_day[$atime]+="$file"$'\n'
    done < <(find . -iregex ".*\.\(mp4\|flv\|mov\|mkv\|webm\|avi\|mpg\|mpeg\)" -type f -print0)

    # Shuffle files within each day and add to all_files array
    for day in $(printf "%s\n" "${!files_by_day[@]}" | sort); do
        IFS=$'\n' read -r -d '' -a files <<< "${files_by_day[$day]}"
        shuffle
        for file in "${files[@]}"; do
            all_files+=("$file")
            all_files_with_dates+=("$(stat -c %x "$file") $file")
        done
    done

    # Print the list of all files with their last access times
    printf 'Files to be played with last access times:\n'
    printf '%s\n' "${all_files_with_dates[@]}"

    # Play all shuffled files with mpv
    printf '%s\0' "${all_files[@]}" | xargs -0 mpv --fs --loop-file=inf --loop-playlist=inf
}
